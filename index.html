<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Î≥¥Ïª¨ Î¶¨Î¨¥Î≤Ñ</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 15px;
            padding: 40px;
            text-align: center;
            margin-bottom: 30px;
            background: rgba(102, 126, 234, 0.05);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .upload-area:hover {
            border-color: #764ba2;
            background: rgba(118, 75, 162, 0.1);
        }

        .upload-area.dragover {
            border-color: #764ba2;
            background: rgba(118, 75, 162, 0.2);
        }

        .upload-text {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 10px;
        }

        .upload-hint {
            font-size: 0.9em;
            color: #999;
        }

        .file-input {
            display: none;
        }

        .method-selector {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .method-btn {
            flex: 1;
            padding: 20px 25px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
            text-align: center;
            min-width: 280px;
            position: relative;
            overflow: hidden;
        }

        .method-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
            transition: left 0.5s ease;
        }

        .method-btn:hover::before {
            left: 100%;
        }

        .method-btn.active {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }

        .method-btn:hover {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }

        .method-title {
            font-size: 1.1em;
            margin-bottom: 8px;
        }

        .method-description {
            font-size: 0.9em;
            opacity: 0.8;
        }

        .process-btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 18px 35px;
            border-radius: 12px;
            font-size: 1.2em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 100%;
            position: relative;
            overflow: hidden;
        }

        .process-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
            transition: left 0.6s ease;
        }

        .process-btn:hover::before {
            left: 100%;
        }

        .process-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.4);
        }

        .process-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .process-btn:disabled::before {
            display: none;
        }

        .progress-container {
            margin: 25px 0;
            display: none;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #f0f0f0;
            border-radius: 4px;
            overflow: hidden;
            margin-bottom: 10px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
            border-radius: 4px;
        }

        .progress-text {
            text-align: center;
            color: #667eea;
            font-weight: bold;
            font-size: 0.9em;
        }

        .audio-player {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.1));
            border-radius: 20px;
            padding: 25px;
            margin-top: 25px;
            display: none;
            border: 1px solid rgba(102, 126, 234, 0.2);
        }

        .audio-player h3 {
            color: #333;
            margin-bottom: 20px;
            text-align: center;
            font-size: 1.3em;
        }

        .audio-section {
            margin-bottom: 20px;
            background: white;
            border-radius: 12px;
            padding: 15px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .audio-section h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1em;
        }

        .audio-section audio {
            width: 100%;
            margin-bottom: 10px;
        }

        .download-section {
            text-align: center;
            margin-top: 20px;
        }

        .download-btn {
            background: linear-gradient(135deg, #28a745, #20c997);
            color: white;
            border: none;
            padding: 12px 25px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(40, 167, 69, 0.3);
        }

        .info-box {
            background: linear-gradient(135deg, rgba(255, 193, 7, 0.1), rgba(255, 152, 0, 0.1));
            border: 1px solid #ffc107;
            border-radius: 15px;
            padding: 20px;
            margin-top: 25px;
            color: #856404;
        }

        .info-title {
            font-weight: bold;
            margin-bottom: 10px;
            color: #b8860b;
        }

        .status {
            text-align: center;
            margin: 20px 0;
            font-weight: bold;
            color: #667eea;
            font-size: 1.1em;
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(102, 126, 234, 0.3);
            border-radius: 50%;
            border-top-color: #667eea;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        @media (max-width: 768px) {
            .container {
                padding: 25px;
                margin: 10px;
            }

            h1 {
                font-size: 2em;
            }

            .method-selector {
                flex-direction: column;
            }

            .method-btn {
                min-width: auto;
            }

            .upload-area {
                padding: 30px 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéµ AI Î≥¥Ïª¨ Î¶¨Î¨¥Î≤Ñ</h1>
        
        <div class="upload-area" id="uploadArea">
            <div class="upload-text">ÏùåÏïÖ ÌååÏùºÏùÑ ÎìúÎûòÍ∑∏ÌïòÍ±∞ÎÇò ÌÅ¥Î¶≠ÌïòÏó¨ ÏóÖÎ°úÎìú</div>
            <div class="upload-hint">ÏßÄÏõê ÌòïÏãù: MP3, WAV, M4A (ÏµúÎåÄ 10MB)</div>
            <input type="file" id="fileInput" class="file-input" accept="audio/*">
        </div>

        <div class="method-selector">
            <button class="method-btn active" data-method="vocal">
                <div class="method-title">üé§ Î≥¥Ïª¨ Ï†úÍ±∞</div>
                <div class="method-description">Î©îÏù∏ Î≥¥Ïª¨Îßå Ï†úÍ±∞ÌïòÍ≥† ÏïÖÍ∏∞ÏôÄ Î∞∞Í≤ΩÏùåÏùÄ Ïú†ÏßÄ</div>
            </button>
            <button class="method-btn" data-method="chorus">
                <div class="method-title">üéµ ÏΩîÎü¨Ïä§ Ï†úÍ±∞</div>
                <div class="method-description">Î≥¥Ïª¨Í≥º ÏΩîÎü¨Ïä§, ÌïòÎ™®ÎãàÍπåÏßÄ Î™®Îëê Ï†úÍ±∞</div>
            </button>
        </div>

        <button class="process-btn" id="processBtn" disabled>ÌååÏùºÏùÑ Î®ºÏ†Ä ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî</button>

        <div class="progress-container" id="progressContainer">
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill"></div>
            </div>
            <div class="progress-text" id="progressText">Ï≤òÎ¶¨ Ï§ë...</div>
        </div>

        <div class="status" id="status"></div>

        <div class="audio-player" id="audioPlayer">
            <h3>üéß Ï≤òÎ¶¨ Í≤∞Í≥º</h3>
            
            <div class="audio-section">
                <h4>üìª ÏõêÎ≥∏ Ïò§ÎîîÏò§</h4>
                <audio id="originalAudio" controls preload="metadata"></audio>
            </div>
            
            <div class="audio-section">
                <h4>‚ú® Ï≤òÎ¶¨Îêú Ïò§ÎîîÏò§</h4>
                <audio id="processedAudio" controls preload="metadata"></audio>
            </div>

            <div class="download-section">
                <button class="download-btn" id="downloadBtn">üíæ Îã§Ïö¥Î°úÎìú</button>
            </div>
        </div>

        <div class="info-box">
            <div class="info-title">üí° ÏÇ¨Ïö© ÌåÅ</div>
            ‚Ä¢ <strong>Î≥¥Ïª¨ Ï†úÍ±∞:</strong> ÏùºÎ∞òÏ†ÅÏù∏ Î≥¥Ïª¨ Ï†úÍ±∞Î°ú Î∞òÏ£ºÎßå ÎÇ®ÍπÅÎãàÎã§<br>
            ‚Ä¢ <strong>ÏΩîÎü¨Ïä§ Ï†úÍ±∞:</strong> Î≥¥Ïª¨, Î∞±Î≥¥Ïª¨, ÌïòÎ™®ÎãàÍπåÏßÄ Î™®Îëê Ï†úÍ±∞ÌïòÏó¨ ÏàúÏàò ÏïÖÍ∏∞ÏùåÎßå ÎÇ®ÍπÅÎãàÎã§<br>
            ‚Ä¢ ÏµúÏ†ÅÏùò Í≤∞Í≥ºÎ•º ÏúÑÌï¥ Í≥†ÌíàÏßà Ïä§ÌÖåÎ†àÏò§ Ïò§ÎîîÏò§Î•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî<br>
            ‚Ä¢ Ï≤òÎ¶¨ ÏãúÍ∞ÑÏùÄ ÌååÏùº Í∏∏Ïù¥Ïóê Îî∞Îùº 1-3Î∂Ñ Ï†ïÎèÑ ÏÜåÏöîÎê©ÎãàÎã§
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>
    <script>
        class AdvancedVocalRemover {
            constructor() {
                this.audioContext = null;
                this.currentMethod = 'vocal';
                this.audioFile = null;
                this.processedAudioBuffer = null;
                this.vocalModel = null;
                this.chorusModel = null;
                this.setupEventListeners();
                this.initializeAI();
            }

            setupEventListeners() {
                const uploadArea = document.getElementById('uploadArea');
                const fileInput = document.getElementById('fileInput');
                const processBtn = document.getElementById('processBtn');
                const methodBtns = document.querySelectorAll('.method-btn');

                // ÌååÏùº ÏóÖÎ°úÎìú Ïù¥Î≤§Ìä∏
                uploadArea.addEventListener('click', () => fileInput.click());
                
                uploadArea.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadArea.classList.add('dragover');
                });
                
                uploadArea.addEventListener('dragleave', () => {
                    uploadArea.classList.remove('dragover');
                });
                
                uploadArea.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadArea.classList.remove('dragover');
                    this.handleFile(e.dataTransfer.files[0]);
                });

                fileInput.addEventListener('change', (e) => {
                    this.handleFile(e.target.files[0]);
                });

                // Ï≤òÎ¶¨ Î∞©Î≤ï ÏÑ†ÌÉù
                methodBtns.forEach(btn => {
                    btn.addEventListener('click', () => {
                        methodBtns.forEach(b => b.classList.remove('active'));
                        btn.classList.add('active');
                        this.currentMethod = btn.dataset.method;
                    });
                });

                // Ï≤òÎ¶¨ ÏãúÏûë Î≤ÑÌäº
                processBtn.addEventListener('click', () => this.processAudio());

                // Îã§Ïö¥Î°úÎìú Î≤ÑÌäº
                document.getElementById('downloadBtn').addEventListener('click', () => {
                    this.downloadProcessedAudio();
                });
            }

            async initializeAI() {
                try {
                    this.updateStatus('<span class="loading-spinner"></span>AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ï§ë...');
                    
                    // Î≥¥Ïª¨ Ï†úÍ±∞ Î™®Îç∏ (U-Net Ïä§ÌÉÄÏùº ÏïÑÌÇ§ÌÖçÏ≤ò)
                    this.vocalModel = await this.createVocalSeparationModel();
                    
                    // ÏΩîÎü¨Ïä§ Ï†úÍ±∞ Î™®Îç∏ (Îçî Í∞ïÎ†•Ìïú Î∂ÑÎ¶¨ Îä•Î†•)
                    this.chorusModel = await this.createChorusSeparationModel();
                    
                    this.updateStatus('ü§ñ AI Î™®Îç∏ Ï§ÄÎπÑ ÏôÑÎ£å');
                    
                } catch (error) {
                    console.error('AI Ï¥àÍ∏∞Ìôî Ïã§Ìå®:', error);
                    this.updateStatus('‚ö†Ô∏è AI Î™®Îç∏ Î°úÎìú Ïã§Ìå® - Í∏∞Î≥∏ Î™®ÎìúÎ°ú ÎèôÏûë');
                }
            }

            async createVocalSeparationModel() {
                // U-Net Ïä§ÌÉÄÏùºÏùò Î≥¥Ïª¨ Î∂ÑÎ¶¨ Î™®Îç∏
                const input = tf.input({shape: [null, 513, 2]});
                
                // Encoder
                let x = tf.layers.conv2d({
                    filters: 32,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const skip1 = x;
                x = tf.layers.maxPooling2d({poolSize: [2, 1]}).apply(x);
                
                x = tf.layers.conv2d({
                    filters: 64,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                const skip2 = x;
                x = tf.layers.maxPooling2d({poolSize: [2, 1]}).apply(x);
                
                // Bottleneck
                x = tf.layers.conv2d({
                    filters: 128,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                // Decoder
                x = tf.layers.upSampling2d({size: [2, 1]}).apply(x);
                x = tf.layers.concatenate().apply([x, skip2]);
                
                x = tf.layers.conv2d({
                    filters: 64,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                x = tf.layers.upSampling2d({size: [2, 1]}).apply(x);
                x = tf.layers.concatenate().apply([x, skip1]);
                
                x = tf.layers.conv2d({
                    filters: 32,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                // Ï∂úÎ†•: Î≥¥Ïª¨Í≥º ÏïÖÍ∏∞Î•º Î∂ÑÎ¶¨ÌïòÎäî ÎßàÏä§ÌÅ¨
                const vocalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'vocal_mask'
                }).apply(x);
                
                const instrumentalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'instrumental_mask'
                }).apply(x);
                
                const model = tf.model({
                    inputs: input,
                    outputs: [vocalMask, instrumentalMask]
                });
                
                model.compile({
                    optimizer: tf.train.adam(0.001),
                    loss: 'meanSquaredError'
                });
                
                return model;
            }

            async createChorusSeparationModel() {
                // Îçî Î≥µÏû°Ìïú Î™®Îç∏Î°ú ÏΩîÎü¨Ïä§ÍπåÏßÄ Ï†úÍ±∞
                const input = tf.input({shape: [null, 513, 2]});
                
                // Multi-scale feature extraction
                const conv1 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const conv2 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [5, 5],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const conv3 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [7, 7],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                let x = tf.layers.concatenate().apply([conv1, conv2, conv3]);
                
                // Deep processing layers
                for (let i = 0; i < 4; i++) {
                    x = tf.layers.conv2d({
                        filters: 64,
                        kernelSize: [3, 3],
                        activation: 'relu',
                        padding: 'same'
                    }).apply(x);
                    
                    x = tf.layers.batchNormalization().apply(x);
                    
                    if (i % 2 === 0) {
                        x = tf.layers.dropout({rate: 0.2}).apply(x);
                    }
                }
                
                // Attention mechanism (simplified)
                const attention = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid'
                }).apply(x);
                
                x = tf.layers.multiply().apply([x, attention]);
                
                // Final separation masks
                const instrumentalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'instrumental_only'
                }).apply(x);
                
                const model = tf.model({
                    inputs: input,
                    outputs: instrumentalMask
                });
                
                model.compile({
                    optimizer: tf.train.adam(0.001),
                    loss: 'meanSquaredError'
                });
                
                return model;
            }

            async handleFile(file) {
                if (!file || !file.type.startsWith('audio/')) {
                    alert('Ïò¨Î∞îÎ•∏ Ïò§ÎîîÏò§ ÌååÏùºÏùÑ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.');
                    return;
                }

                if (file.size > 10 * 1024 * 1024) {
                    alert('ÌååÏùº ÌÅ¨Í∏∞Îäî 10MBÎ•º Ï¥àÍ≥ºÌï† Ïàò ÏóÜÏäµÎãàÎã§.');
                    return;
                }

                this.audioFile = file;
                this.updateStatus(`üìÅ ÌååÏùº Î°úÎìúÎê®: ${file.name}`);
                
                // AudioContext Ï¥àÍ∏∞Ìôî
                if (!this.audioContext) {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // ÏõêÎ≥∏ Ïò§ÎîîÏò§ ÌëúÏãú
                const originalAudio = document.getElementById('originalAudio');
                originalAudio.src = URL.createObjectURL(file);

                // Ï≤òÎ¶¨ Î≤ÑÌäº ÌôúÏÑ±Ìôî
                const processBtn = document.getElementById('processBtn');
                processBtn.disabled = false;
                processBtn.innerHTML = this.currentMethod === 'vocal' ? 
                    'üé§ Î≥¥Ïª¨ Ï†úÍ±∞ ÏãúÏûë' : 'üéµ ÏΩîÎü¨Ïä§ Ï†úÍ±∞ ÏãúÏûë';
            }

            async processAudio() {
                if (!this.audioFile) return;

                try {
                    this.showProgress();
                    this.updateStatus('<span class="loading-spinner"></span>Ïò§ÎîîÏò§ Î∂ÑÏÑù Ï§ë...');
                    this.updateProgress(10, 'Ïò§ÎîîÏò§ ÌååÏùº ÏùΩÎäî Ï§ë...');

                    // ÌååÏùºÏùÑ ArrayBufferÎ°ú ÏùΩÍ∏∞
                    const arrayBuffer = await this.audioFile.arrayBuffer();
                    this.updateProgress(20, 'Ïò§ÎîîÏò§ ÎîîÏΩîÎî© Ï§ë...');

                    // AudioBufferÎ°ú ÎîîÏΩîÎìú
                    const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                    this.updateProgress(30, 'AI Î™®Îç∏ Ï§ÄÎπÑ Ï§ë...');

                    let processedBuffer;
                    
                    if (this.currentMethod === 'vocal') {
                        this.updateProgress(40, 'Î≥¥Ïª¨ Î∂ÑÎ¶¨ Ï≤òÎ¶¨ Ï§ë...');
                        processedBuffer = await this.performVocalSeparation(audioBuffer);
                    } else {
                        this.updateProgress(40, 'ÏΩîÎü¨Ïä§ Î∂ÑÎ¶¨ Ï≤òÎ¶¨ Ï§ë...');
                        processedBuffer = await this.performChorusSeparation(audioBuffer);
                    }

                    this.updateProgress(80, 'Í≤∞Í≥º ÌååÏùº ÏÉùÏÑ± Ï§ë...');

                    // Ï≤òÎ¶¨Îêú Ïò§ÎîîÏò§Î•º BlobÏúºÎ°ú Î≥ÄÌôò
                    const processedBlob = await this.audioBufferToBlob(processedBuffer);
                    this.updateProgress(100, 'Ï≤òÎ¶¨ ÏôÑÎ£å!');

                    // Í≤∞Í≥º ÌëúÏãú
                    this.displayResult(processedBlob, processedBuffer);
                    this.updateStatus('‚úÖ Ï≤òÎ¶¨Í∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!');

                } catch (error) {
                    console.error('Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò:', error);
                    this.updateStatus('‚ùå Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: ' + error.message);
                    this.hideProgress();
                }
            }

            async performVocalSeparation(audioBuffer) {
                // Ïä§ÌÖåÎ†àÏò§ Ï±ÑÎÑê Î∂ÑÎ¶¨
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.numberOfChannels > 1 ? 
                    audioBuffer.getChannelData(1) : leftChannel;

                // STFT Î≥ÄÌôò
                const stftData = await this.performSTFT(leftChannel, rightChannel);
                this.updateProgress(50, 'AI Î≥¥Ïª¨ Î∂ÑÎ¶¨ Ï§ë...');

                // AI Î™®Îç∏ Ï†ÅÏö© (Ïã§Ï†ú ÌôòÍ≤ΩÏóêÏÑúÎäî ÌõàÎ†®Îêú Î™®Îç∏ ÏÇ¨Ïö©)
                let separatedData;
                if (this.vocalModel) {
                    try {
                        const [vocalMask, instrumentalMask] = this.vocalModel.predict(stftData);
                        // ÏïÖÍ∏∞ ÎßàÏä§ÌÅ¨ Ï†ÅÏö©
                        separatedData = await this.applyMask(stftData, instrumentalMask);
                        vocalMask.dispose();
                        instrumentalMask.dispose();
                    } catch (error) {
                        console.warn('AI Î™®Îç∏ Ï†ÅÏö© Ïã§Ìå®, Í≥†Í∏â ÏïåÍ≥†Î¶¨Ï¶ò ÏÇ¨Ïö©:', error);
                        separatedData = await this.advancedVocalRemoval(stftData);
                    }
                } else {
                    separatedData = await this.advancedVocalRemoval(stftData);
                }

                this.updateProgress(70, 'ISTFT Î≥ÄÌôò Ï§ë...');
                
                // ISTFTÎ°ú ÏãúÍ∞Ñ ÎèÑÎ©îÏù∏ Î≥µÏõê
                const processedBuffer = await this.performISTFT(separatedData, audioBuffer.sampleRate);
                
                stftData.dispose();
                if (separatedData !== stftData) separatedData.dispose();
                
                return processedBuffer;
            }

            async performChorusSeparation(audioBuffer) {
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.numberOfChannels > 1 ? 
                    audioBuffer.getChannelData(1) : leftChannel;

                const stftData = await this.performSTFT(leftChannel, rightChannel);
                this.updateProgress(50, 'AI ÏΩîÎü¨Ïä§ Î∂ÑÎ¶¨ Ï§ë...');

                let separatedData;
                if (this.chorusModel) {
                    try {
                        const instrumentalMask = this.chorusModel.predict(stftData);
                        separatedData = await this.applyMask(stftData, instrumentalMask);
                        instrumentalMask.dispose();
                    } catch (error) {
                        console.warn('AI ÏΩîÎü¨Ïä§ Î™®Îç∏ Ï†ÅÏö© Ïã§Ìå®, Í∞ïÌôî ÏïåÍ≥†Î¶¨Ï¶ò ÏÇ¨Ïö©:', error);
                        separatedData = await this.advancedChorusRemoval(stftData);
                    }
                } else {
                    separatedData = await this.advancedChorusRemoval(stftData);
                }

                this.updateProgress(70, 'ISTFT Î≥ÄÌôò Ï§ë...');
                
                const processedBuffer = await this.performISTFT(separatedData, audioBuffer.sampleRate);
                
                stftData.dispose();
                if (separatedData !== stftData) separatedData.dispose();
                
                return processedBuffer;
            }

            async performSTFT(leftChannel, rightChannel) {
                const windowSize = 2048;
                const hopSize = windowSize / 4;
                const numFrames = Math.floor((leftChannel.length - windowSize) / hopSize) + 1;
                
                // Ïã§Ï†ú FFT Íµ¨ÌòÑ (Í∞ÑÏÜåÌôîÎêú Î≤ÑÏ†Ñ)
                const spectrogram = new Float32Array(numFrames * (windowSize / 2 + 1) * 2); // Ïã§ÏàòÎ∂Ä, ÌóàÏàòÎ∂Ä
                
                // Ìï¥Î∞ç ÏúàÎèÑÏö∞
                const window = new Float32Array(windowSize);
                for (let i = 0; i < windowSize; i++) {
                    window[i] = 0.54 - 0.46 * Math.cos(2 * Math.PI * i / (windowSize - 1));
                }
                
                for (let frame = 0; frame < numFrames; frame++) {
                    const startIdx = frame * hopSize;
                    
                    // ÏúàÎèÑÏö∞ Ï†ÅÏö© ÌõÑ FFT (Ïã§Ï†úÎ°úÎäî Îçî Ï†ïÍµêÌïú FFT ÌïÑÏöî)
                    for (let bin = 0; bin < windowSize / 2 + 1; bin++) {
                        const idx = frame * (windowSize / 2 + 1) * 2 + bin * 2;
                        
                        // Ï¢åÏö∞ Ï±ÑÎÑêÏùò Î≥µÏÜåÏàò Ïä§ÌéôÌä∏Î°úÍ∑∏Îû® ÏÉùÏÑ±
                        let realPart = 0, imagPart = 0;
                        for (let k = 0; k < windowSize && startIdx + k < leftChannel.length; k++) {
                            const angle = -2 * Math.PI * bin * k / windowSize;
                            const leftSample = leftChannel[startIdx + k] * window[k];
                            const rightSample = rightChannel[startIdx + k] * window[k];
                            const sample = (leftSample + rightSample) / 2;
                            
                            realPart += sample * Math.cos(angle);
                            imagPart += sample * Math.sin(angle);
                        }
                        
                        spectrogram[idx] = realPart;
                        spectrogram[idx + 1] = imagPart;
                    }
                }
                
                return tf.tensor3d(spectrogram, [1, numFrames, (windowSize / 2 + 1) * 2]);
            }

            async performISTFT(stftData, sampleRate) {
                const windowSize = 2048;
                const hopSize = windowSize / 4;
                const stftShape = stftData.shape;
                const numFrames = stftShape[1];
                const numBins = stftShape[2] / 2;
                
                const outputLength = (numFrames - 1) * hopSize + windowSize;
                const outputBuffer = this.audioContext.createBuffer(1, outputLength, sampleRate);
                const outputData = outputBuffer.getChannelData(0);
                
                const stftArray = await stftData.data();
                
                // Ìï¥Î∞ç ÏúàÎèÑÏö∞
                const window = new Float32Array(windowSize);
                for (let i = 0; i < windowSize; i++) {
                    window[i] = 0.54 - 0.46 * Math.cos(2 * Math.PI * i / (windowSize - 1));
                }
                
                for (let frame = 0; frame < numFrames; frame++) {
                    const startIdx = frame * hopSize;
                    
                    // IFFT (Í∞ÑÏÜåÌôîÎêú Íµ¨ÌòÑ)
                    for (let n = 0; n < windowSize && startIdx + n < outputLength; n++) {
                        let sample = 0;
                        for (let bin = 0; bin < numBins; bin++) {
                            const idx = frame * numBins * 2 + bin * 2;
                            const real = stftArray[idx];
                            const imag = stftArray[idx + 1];
                            const angle = 2 * Math.PI * bin * n / windowSize;
                            sample += real * Math.cos(angle) - imag * Math.sin(angle);
                        }
                        outputData[startIdx + n] += sample * window[n] / windowSize;
                    }
                }
                
                return outputBuffer;
            }

            async applyMask(stftData, mask) {
                const maskArray = await mask.data();
                const stftArray = await stftData.data();
                const maskedData = new Float32Array(stftArray.length);
                
                for (let i = 0; i < stftArray.length; i += 2) {
                    const maskValue = maskArray[Math.floor(i / 2)];
                    maskedData[i] = stftArray[i] * maskValue;
                    maskedData[i + 1] = stftArray[i + 1] * maskValue;
                }
                
                return tf.tensor3d(maskedData, stftData.shape);
            }

            async advancedVocalRemoval(stftData) {
                const stftArray = await stftData.data();
                const processedData = new Float32Array(stftArray.length);
                const shape = stftData.shape;
                const numFrames = shape[1];
                const numBins = shape[2] / 2;
                
                // Í≥†Í∏â Î≥¥Ïª¨ Ï†úÍ±∞ ÏïåÍ≥†Î¶¨Ï¶ò
                for (let frame = 0; frame < numFrames; frame++) {
                    for (let bin = 0; bin < numBins; bin++) {
                        const idx = frame * numBins * 2 + bin * 2;
                        const real = stftArray[idx];
                        const imag = stftArray[idx + 1];
                        const magnitude = Math.sqrt(real * real + imag * imag);
                        const phase = Math.atan2(imag, real);
                        
                        // Ï§ëÏïô Ï£ºÌååÏàò ÎåÄÏó≠ÏóêÏÑú Î≥¥Ïª¨ Ï†úÍ±∞ (Í∞úÏÑ†Îêú ÏïåÍ≥†Î¶¨Ï¶ò)
                        let attenuation = 1.0;
                        if (bin > numBins * 0.1 && bin < numBins * 0.8) {
                            // Ï£ºÌååÏàò ÏÑ†ÌÉùÏ†Å Í∞êÏá†
                            const vocalRange = Math.exp(-Math.pow((bin - numBins * 0.3) / (numBins * 0.2), 2));
                            attenuation = Math.max(0.1, 1.0 - vocalRange * 0.9);
                        }
                        
                        const newMagnitude = magnitude * attenuation;
                        processedData[idx] = newMagnitude * Math.cos(phase);
                        processedData[idx + 1] = newMagnitude * Math.sin(phase);
                    }
                }
                
                return tf.tensor3d(processedData, shape);
            }

            async advancedChorusRemoval(stftData) {
                const stftArray = await stftData.data();
                const processedData = new Float32Array(stftArray.length);
                const shape = stftData.shape;
                const numFrames = shape[1];
                const numBins = shape[2] / 2;
                
                // Îçî Í∞ïÎ†•Ìïú ÏΩîÎü¨Ïä§ Ï†úÍ±∞ ÏïåÍ≥†Î¶¨Ï¶ò
                for (let frame = 0; frame < numFrames; frame++) {
                    for (let bin = 0; bin < numBins; bin++) {
                        const idx = frame * numBins * 2 + bin * 2;
                        const real = stftArray[idx];
                        const imag = stftArray[idx + 1];
                        const magnitude = Math.sqrt(real * real + imag * imag);
                        const phase = Math.atan2(imag, real);
                        
                        // Î≥¥Ïª¨ Î∞è ÏΩîÎü¨Ïä§ Ï£ºÌååÏàò ÎåÄÏó≠ÏóêÏÑú Í∞ïÌïú Í∞êÏá†
                        let attenuation = 1.0;
                        
                        // Í∏∞Î≥∏ Î≥¥Ïª¨ ÎåÄÏó≠ (200Hz - 2kHz)
                        if (bin > numBins * 0.05 && bin < numBins * 0.6) {
                            const vocalAttenuation = Math.exp(-Math.pow((bin - numBins * 0.25) / (numBins * 0.15), 2));
                            attenuation *= Math.max(0.05, 1.0 - vocalAttenuation * 0.95);
                        }
                        
                        // ÏΩîÎü¨Ïä§ Î∞è ÌïòÎ™®Îãà ÎåÄÏó≠ (Îçî ÎÑìÏùÄ Î≤îÏúÑ)
                        if (bin > numBins * 0.08 && bin < numBins * 0.75) {
                            const chorusAttenuation = Math.exp(-Math.pow((bin - numBins * 0.4) / (numBins * 0.25), 2));
                            attenuation *= Math.max(0.08, 1.0 - chorusAttenuation * 0.85);
                        }
                        
                        // Í≥†Ï°∞Ìåå Ï†úÍ±∞
                        for (let harmonic = 2; harmonic <= 4; harmonic++) {
                            const harmonicBin = bin / harmonic;
                            if (harmonicBin > numBins * 0.1 && harmonicBin < numBins * 0.3) {
                                attenuation *= 0.7;
                            }
                        }
                        
                        const newMagnitude = magnitude * attenuation;
                        processedData[idx] = newMagnitude * Math.cos(phase);
                        processedData[idx + 1] = newMagnitude * Math.sin(phase);
                    }
                }
                
                return tf.tensor3d(processedData, shape);
            }

            async audioBufferToBlob(audioBuffer) {
                const numberOfChannels = audioBuffer.numberOfChannels;
                const length = audioBuffer.length;
                const sampleRate = audioBuffer.sampleRate;
                
                // WAV ÌååÏùº ÏÉùÏÑ±
                const buffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
                const view = new DataView(buffer);
                
                // WAV Ìó§Îçî ÏûëÏÑ±
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };
                
                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * numberOfChannels * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, numberOfChannels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * numberOfChannels * 2, true);
                view.setUint16(32, numberOfChannels * 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * numberOfChannels * 2, true);
                
                // Ïò§ÎîîÏò§ Îç∞Ïù¥ÌÑ∞ ÏûëÏÑ± (Ï†ïÍ∑úÌôî Î∞è ÌÅ¥Î¶¨Ìïë Ï†ÅÏö©)
                let offset = 44;
                for (let i = 0; i < length; i++) {
                    for (let channel = 0; channel < numberOfChannels; channel++) {
                        let sample = audioBuffer.getChannelData(channel)[i];
                        
                        // ÎÖ∏Ïù¥Ï¶à Í≤åÏù¥Ìä∏ Ï†ÅÏö©
                        if (Math.abs(sample) < 0.001) sample = 0;
                        
                        // ÏÜåÌîÑÌä∏ ÌÅ¥Î¶¨Ìïë
                        sample = Math.max(-1, Math.min(1, sample));
                        if (sample > 0.95) sample = 0.95 + (sample - 0.95) * 0.2;
                        if (sample < -0.95) sample = -0.95 + (sample + 0.95) * 0.2;
                        
                        const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                        view.setInt16(offset, intSample, true);
                        offset += 2;
                    }
                }
                
                return new Blob([buffer], { type: 'audio/wav' });
            }

            displayResult(processedBlob, processedBuffer) {
                this.processedAudioBuffer = processedBuffer;
                
                const processedAudio = document.getElementById('processedAudio');
                processedAudio.src = URL.createObjectURL(processedBlob);
                
                // Í≤∞Í≥º Ìå®ÎÑê ÌëúÏãú
                document.getElementById('audioPlayer').style.display = 'block';
                
                // Î∂ÄÎìúÎü¨Ïö¥ Ïä§ÌÅ¨Î°§
                document.getElementById('audioPlayer').scrollIntoView({
                    behavior: 'smooth',
                    block: 'center'
                });
            }

            downloadProcessedAudio() {
                if (!this.processedAudioBuffer) return;
                
                this.audioBufferToBlob(this.processedAudioBuffer).then(blob => {
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    
                    const methodName = this.currentMethod === 'vocal' ? 'vocal_removed' : 'chorus_removed';
                    const timestamp = new Date().toISOString().slice(0, 19).replace(/[:\-]/g, '');
                    a.download = `${methodName}_${timestamp}.wav`;
                    
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                    
                    this.updateStatus('üíæ ÌååÏùºÏù¥ Îã§Ïö¥Î°úÎìúÎêòÏóàÏäµÎãàÎã§!');
                });
            }

            updateStatus(message) {
                document.getElementById('status').innerHTML = message;
            }

            showProgress() {
                document.getElementById('progressContainer').style.display = 'block';
                document.getElementById('processBtn').disabled = true;
            }

            hideProgress() {
                document.getElementById('progressContainer').style.display = 'none';
                document.getElementById('processBtn').disabled = false;
            }

            updateProgress(percent, text = '') {
                document.getElementById('progressFill').style.width = percent + '%';
                if (text) {
                    document.getElementById('progressText').textContent = text;
                }
                
                if (percent >= 100) {
                    setTimeout(() => {
                        this.hideProgress();
                    }, 2000);
                }
            }
        }

        // Ïï± Ï¥àÍ∏∞Ìôî
        document.addEventListener('DOMContentLoaded', () => {
            new AdvancedVocalRemover();
        });
    </script>
</body>
</html>