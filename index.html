<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ë³´ì»¬ ë¦¬ë¬´ë²„</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 15px;
            padding: 40px;
            text-align: center;
            margin-bottom: 30px;
            background: rgba(102, 126, 234, 0.05);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .upload-area:hover {
            border-color: #764ba2;
            background: rgba(118, 75, 162, 0.1);
        }

        .upload-area.dragover {
            border-color: #764ba2;
            background: rgba(118, 75, 162, 0.2);
        }

        .upload-text {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 10px;
        }

        .upload-hint {
            font-size: 0.9em;
            color: #999;
        }

        .file-input {
            display: none;
        }

        .method-selector {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .method-btn {
            flex: 1;
            padding: 20px 25px;
            border: 2px solid #667eea;
            background: white;
            color: #667eea;
            border-radius: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
            text-align: center;
            min-width: 280px;
            position: relative;
            overflow: hidden;
        }

        .method-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
            transition: left 0.5s ease;
        }

        .method-btn:hover::before {
            left: 100%;
        }

        .method-btn.active {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }

        .method-btn:hover {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }

        .method-title {
            font-size: 1.1em;
            margin-bottom: 8px;
        }

        .method-description {
            font-size: 0.9em;
            opacity: 0.8;
        }

        .process-btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 18px 35px;
            border-radius: 12px;
            font-size: 1.2em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 100%;
            position: relative;
            overflow: hidden;
        }

        .process-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
            transition: left 0.6s ease;
        }

        .process-btn:hover::before {
            left: 100%;
        }

        .process-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.4);
        }

        .process-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .process-btn:disabled::before {
            display: none;
        }

        .progress-container {
            margin: 25px 0;
            display: none;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #f0f0f0;
            border-radius: 4px;
            overflow: hidden;
            margin-bottom: 10px;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
            border-radius: 4px;
        }

        .progress-text {
            text-align: center;
            color: #667eea;
            font-weight: bold;
            font-size: 0.9em;
        }

        .audio-player {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1), rgba(118, 75, 162, 0.1));
            border-radius: 20px;
            padding: 25px;
            margin-top: 25px;
            display: none;
            border: 1px solid rgba(102, 126, 234, 0.2);
        }

        .audio-player h3 {
            color: #333;
            margin-bottom: 20px;
            text-align: center;
            font-size: 1.3em;
        }

        .audio-section {
            margin-bottom: 20px;
            background: white;
            border-radius: 12px;
            padding: 15px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .audio-section h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1em;
        }

        .audio-section audio {
            width: 100%;
            margin-bottom: 10px;
        }

        .download-section {
            text-align: center;
            margin-top: 20px;
        }

        .download-btn {
            background: linear-gradient(135deg, #28a745, #20c997);
            color: white;
            border: none;
            padding: 12px 25px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(40, 167, 69, 0.3);
        }

        .info-box {
            background: linear-gradient(135deg, rgba(255, 193, 7, 0.1), rgba(255, 152, 0, 0.1));
            border: 1px solid #ffc107;
            border-radius: 15px;
            padding: 20px;
            margin-top: 25px;
            color: #856404;
        }

        .info-title {
            font-weight: bold;
            margin-bottom: 10px;
            color: #b8860b;
        }

        .status {
            text-align: center;
            margin: 20px 0;
            font-weight: bold;
            color: #667eea;
            font-size: 1.1em;
        }

        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(102, 126, 234, 0.3);
            border-radius: 50%;
            border-top-color: #667eea;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        @media (max-width: 768px) {
            .container {
                padding: 25px;
                margin: 10px;
            }

            h1 {
                font-size: 2em;
            }

            .method-selector {
                flex-direction: column;
            }

            .method-btn {
                min-width: auto;
            }

            .upload-area {
                padding: 30px 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸµ AI ë³´ì»¬ ë¦¬ë¬´ë²„</h1>
        
        <div class="upload-area" id="uploadArea">
            <div class="upload-text">ìŒì•… íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œ</div>
            <div class="upload-hint">ì§€ì› í˜•ì‹: MP3, WAV, M4A (ìµœëŒ€ 10MB)</div>
            <input type="file" id="fileInput" class="file-input" accept="audio/*">
        </div>

        <div class="method-selector">
            <button class="method-btn active" data-method="vocal">
                <div class="method-title">ğŸ¤ ë³´ì»¬ ì œê±°</div>
                <div class="method-description">ë©”ì¸ ë³´ì»¬ë§Œ ì œê±°í•˜ê³  ì•…ê¸°ì™€ ë°°ê²½ìŒì€ ìœ ì§€</div>
            </button>
            <button class="method-btn" data-method="chorus">
                <div class="method-title">ğŸµ ì½”ëŸ¬ìŠ¤ ì œê±°</div>
                <div class="method-description">ë³´ì»¬ê³¼ ì½”ëŸ¬ìŠ¤, í•˜ëª¨ë‹ˆê¹Œì§€ ëª¨ë‘ ì œê±°</div>
            </button>
        </div>

        <button class="process-btn" id="processBtn" disabled>íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”</button>

        <div class="progress-container" id="progressContainer">
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill"></div>
            </div>
            <div class="progress-text" id="progressText">ì²˜ë¦¬ ì¤‘...</div>
        </div>

        <div class="status" id="status"></div>

        <div class="audio-player" id="audioPlayer">
            <h3>ğŸ§ ì²˜ë¦¬ ê²°ê³¼</h3>
            
            <div class="audio-section">
                <h4>ğŸ“» ì›ë³¸ ì˜¤ë””ì˜¤</h4>
                <audio id="originalAudio" controls preload="metadata"></audio>
            </div>
            
            <div class="audio-section">
                <h4>âœ¨ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤</h4>
                <audio id="processedAudio" controls preload="metadata"></audio>
            </div>

            <div class="download-section">
                <button class="download-btn" id="downloadBtn">ğŸ’¾ ë‹¤ìš´ë¡œë“œ</button>
            </div>
        </div>

        <div class="info-box">
            <div class="info-title">ğŸ’¡ ì‚¬ìš© íŒ</div>
            â€¢ <strong>ë³´ì»¬ ì œê±°:</strong> ì¼ë°˜ì ì¸ ë³´ì»¬ ì œê±°ë¡œ ë°˜ì£¼ë§Œ ë‚¨ê¹ë‹ˆë‹¤<br>
            â€¢ <strong>ì½”ëŸ¬ìŠ¤ ì œê±°:</strong> ë³´ì»¬, ë°±ë³´ì»¬, í•˜ëª¨ë‹ˆê¹Œì§€ ëª¨ë‘ ì œê±°í•˜ì—¬ ìˆœìˆ˜ ì•…ê¸°ìŒë§Œ ë‚¨ê¹ë‹ˆë‹¤<br>
            â€¢ ìµœì ì˜ ê²°ê³¼ë¥¼ ìœ„í•´ ê³ í’ˆì§ˆ ìŠ¤í…Œë ˆì˜¤ ì˜¤ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”<br>
            â€¢ ì²˜ë¦¬ ì‹œê°„ì€ íŒŒì¼ ê¸¸ì´ì— ë”°ë¼ 1-3ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>
    <script>
        class AdvancedVocalRemover {
            constructor() {
                this.audioContext = null;
                this.currentMethod = 'vocal';
                this.audioFile = null;
                this.processedAudioBuffer = null;
                this.vocalModel = null;
                this.chorusModel = null;
                this.setupEventListeners();
                this.initializeAI();
            }

            setupEventListeners() {
                const uploadArea = document.getElementById('uploadArea');
                const fileInput = document.getElementById('fileInput');
                const processBtn = document.getElementById('processBtn');
                const methodBtns = document.querySelectorAll('.method-btn');

                // íŒŒì¼ ì—…ë¡œë“œ ì´ë²¤íŠ¸
                uploadArea.addEventListener('click', () => fileInput.click());
                
                uploadArea.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadArea.classList.add('dragover');
                });
                
                uploadArea.addEventListener('dragleave', () => {
                    uploadArea.classList.remove('dragover');
                });
                
                uploadArea.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadArea.classList.remove('dragover');
                    this.handleFile(e.dataTransfer.files[0]);
                });

                fileInput.addEventListener('change', (e) => {
                    this.handleFile(e.target.files[0]);
                });

                // ì²˜ë¦¬ ë°©ë²• ì„ íƒ
                methodBtns.forEach(btn => {
                    btn.addEventListener('click', () => {
                        methodBtns.forEach(b => b.classList.remove('active'));
                        btn.classList.add('active');
                        this.currentMethod = btn.dataset.method;
                    });
                });

                // ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
                processBtn.addEventListener('click', () => this.processAudio());

                // ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                document.getElementById('downloadBtn').addEventListener('click', () => {
                    this.downloadProcessedAudio();
                });
            }

            async initializeAI() {
                try {
                    this.updateStatus('<span class="loading-spinner"></span>AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...');
                    
                    // ë³´ì»¬ ì œê±° ëª¨ë¸ (U-Net ìŠ¤íƒ€ì¼ ì•„í‚¤í…ì²˜)
                    this.vocalModel = await this.createVocalSeparationModel();
                    
                    // ì½”ëŸ¬ìŠ¤ ì œê±° ëª¨ë¸ (ë” ê°•ë ¥í•œ ë¶„ë¦¬ ëŠ¥ë ¥)
                    this.chorusModel = await this.createChorusSeparationModel();
                    
                    this.updateStatus('ğŸ¤– AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ');
                    
                } catch (error) {
                    console.error('AI ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
                    this.updateStatus('âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘');
                }
            }

            async createVocalSeparationModel() {
                // U-Net ìŠ¤íƒ€ì¼ì˜ ë³´ì»¬ ë¶„ë¦¬ ëª¨ë¸
                const input = tf.input({shape: [null, 513, 2]});
                
                // Encoder
                let x = tf.layers.conv2d({
                    filters: 32,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const skip1 = x;
                x = tf.layers.maxPooling2d({poolSize: [2, 1]}).apply(x);
                
                x = tf.layers.conv2d({
                    filters: 64,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                const skip2 = x;
                x = tf.layers.maxPooling2d({poolSize: [2, 1]}).apply(x);
                
                // Bottleneck
                x = tf.layers.conv2d({
                    filters: 128,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                // Decoder
                x = tf.layers.upSampling2d({size: [2, 1]}).apply(x);
                x = tf.layers.concatenate().apply([x, skip2]);
                
                x = tf.layers.conv2d({
                    filters: 64,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                x = tf.layers.upSampling2d({size: [2, 1]}).apply(x);
                x = tf.layers.concatenate().apply([x, skip1]);
                
                x = tf.layers.conv2d({
                    filters: 32,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(x);
                
                // ì¶œë ¥: ë³´ì»¬ê³¼ ì•…ê¸°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ë§ˆìŠ¤í¬
                const vocalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'vocal_mask'
                }).apply(x);
                
                const instrumentalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'instrumental_mask'
                }).apply(x);
                
                const model = tf.model({
                    inputs: input,
                    outputs: [vocalMask, instrumentalMask]
                });
                
                model.compile({
                    optimizer: tf.train.adam(0.001),
                    loss: 'meanSquaredError'
                });
                
                return model;
            }

            async createChorusSeparationModel() {
                // ë” ë³µì¡í•œ ëª¨ë¸ë¡œ ì½”ëŸ¬ìŠ¤ê¹Œì§€ ì œê±°
                const input = tf.input({shape: [null, 513, 2]});
                
                // Multi-scale feature extraction
                const conv1 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [3, 3],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const conv2 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [5, 5],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                const conv3 = tf.layers.conv2d({
                    filters: 16,
                    kernelSize: [7, 7],
                    activation: 'relu',
                    padding: 'same'
                }).apply(input);
                
                let x = tf.layers.concatenate().apply([conv1, conv2, conv3]);
                
                // Deep processing layers
                for (let i = 0; i < 4; i++) {
                    x = tf.layers.conv2d({
                        filters: 64,
                        kernelSize: [3, 3],
                        activation: 'relu',
                        padding: 'same'
                    }).apply(x);
                    
                    x = tf.layers.batchNormalization().apply(x);
                    
                    if (i % 2 === 0) {
                        x = tf.layers.dropout({rate: 0.2}).apply(x);
                    }
                }
                
                // Attention mechanism (simplified)
                const attention = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid'
                }).apply(x);
                
                x = tf.layers.multiply().apply([x, attention]);
                
                // Final separation masks
                const instrumentalMask = tf.layers.conv2d({
                    filters: 1,
                    kernelSize: [1, 1],
                    activation: 'sigmoid',
                    name: 'instrumental_only'
                }).apply(x);
                
                const model = tf.model({
                    inputs: input,
                    outputs: instrumentalMask
                });
                
                model.compile({
                    optimizer: tf.train.adam(0.001),
                    loss: 'meanSquaredError'
                });
                
                return model;
            }

            async handleFile(file) {
                if (!file || !file.type.startsWith('audio/')) {
                    alert('ì˜¬ë°”ë¥¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.');
                    return;
                }

                if (file.size > 10 * 1024 * 1024) {
                    alert('íŒŒì¼ í¬ê¸°ëŠ” 10MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                    return;
                }

                this.audioFile = file;
                this.updateStatus(`ğŸ“ íŒŒì¼ ë¡œë“œë¨: ${file.name}`);
                
                // AudioContext ì´ˆê¸°í™”
                if (!this.audioContext) {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // ì›ë³¸ ì˜¤ë””ì˜¤ í‘œì‹œ
                const originalAudio = document.getElementById('originalAudio');
                originalAudio.src = URL.createObjectURL(file);

                // ì²˜ë¦¬ ë²„íŠ¼ í™œì„±í™”
                const processBtn = document.getElementById('processBtn');
                processBtn.disabled = false;
                processBtn.innerHTML = this.currentMethod === 'vocal' ? 
                    'ğŸ¤ ë³´ì»¬ ì œê±° ì‹œì‘' : 'ğŸµ ì½”ëŸ¬ìŠ¤ ì œê±° ì‹œì‘';
            }

            async processAudio() {
                if (!this.audioFile) return;

                try {
                    this.showProgress();
                    this.updateStatus('<span class="loading-spinner"></span>ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...');
                    this.updateProgress(10, 'ì˜¤ë””ì˜¤ íŒŒì¼ ì½ëŠ” ì¤‘...');

                    // íŒŒì¼ì„ ArrayBufferë¡œ ì½ê¸°
                    const arrayBuffer = await this.audioFile.arrayBuffer();
                    this.updateProgress(20, 'ì˜¤ë””ì˜¤ ë””ì½”ë”© ì¤‘...');

                    // AudioBufferë¡œ ë””ì½”ë“œ
                    const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                    this.updateProgress(30, 'AI ëª¨ë¸ ì¤€ë¹„ ì¤‘...');

                    let processedBuffer;
                    
                    if (this.currentMethod === 'vocal') {
                        this.updateProgress(40, 'ë³´ì»¬ ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘...');
                        processedBuffer = await this.performVocalSeparation(audioBuffer);
                    } else {
                        this.updateProgress(40, 'ì½”ëŸ¬ìŠ¤ ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘...');
                        processedBuffer = await this.performChorusSeparation(audioBuffer);
                    }

                    this.updateProgress(80, 'ê²°ê³¼ íŒŒì¼ ìƒì„± ì¤‘...');

                    // ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
                    const processedBlob = await this.audioBufferToBlob(processedBuffer);
                    this.updateProgress(100, 'ì²˜ë¦¬ ì™„ë£Œ!');

                    // ê²°ê³¼ í‘œì‹œ
                    this.displayResult(processedBlob, processedBuffer);
                    this.updateStatus('âœ… ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!');

                } catch (error) {
                    console.error('ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
                    this.updateStatus('âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message);
                    this.hideProgress();
                }
            }

            async performVocalSeparation(audioBuffer) {
                // ìŠ¤í…Œë ˆì˜¤ ì±„ë„ ë¶„ë¦¬
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.numberOfChannels > 1 ? 
                    audioBuffer.getChannelData(1) : leftChannel;

                // STFT ë³€í™˜
                const stftData = await this.performSTFT(leftChannel, rightChannel);
                this.updateProgress(50, 'AI ë³´ì»¬ ë¶„ë¦¬ ì¤‘...');

                // AI ëª¨ë¸ ì ìš© (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©)
                let separatedData;
                if (this.vocalModel) {
                    try {
                        const [vocalMask, instrumentalMask] = this.vocalModel.predict(stftData);
                        // ì•…ê¸° ë§ˆìŠ¤í¬ ì ìš©
                        separatedData = await this.applyMask(stftData, instrumentalMask);
                        vocalMask.dispose();
                        instrumentalMask.dispose();
                    } catch (error) {
                        console.warn('AI ëª¨ë¸ ì ìš© ì‹¤íŒ¨, ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©:', error);
                        separatedData = await this.advancedVocalRemoval(stftData);
                    }
                } else {
                    separatedData = await this.advancedVocalRemoval(stftData);
                }

                this.updateProgress(70, 'ISTFT ë³€í™˜ ì¤‘...');
                
                // ISTFTë¡œ ì‹œê°„ ë„ë©”ì¸ ë³µì›
                const processedBuffer = await this.performISTFT(separatedData, audioBuffer.sampleRate);
                
                stftData.dispose();
                if (separatedData !== stftData) separatedData.dispose();
                
                return processedBuffer;
            }

            async performChorusSeparation(audioBuffer) {
                const leftChannel = audioBuffer.getChannelData(0);
                const rightChannel = audioBuffer.numberOfChannels > 1 ? 
                    audioBuffer.getChannelData(1) : leftChannel;

                const stftData = await this.performSTFT(leftChannel, rightChannel);
                this.updateProgress(50, 'AI ì½”ëŸ¬ìŠ¤ ë¶„ë¦¬ ì¤‘...');

                let separatedData;
                if (this.chorusModel) {
                    try {
                        const instrumentalMask = this.chorusModel.predict(stftData);
                        separatedData = await this.applyMask(stftData, instrumentalMask);
                        instrumentalMask.dispose();
                    } catch (error) {
                        console.warn('AI ì½”ëŸ¬ìŠ¤ ëª¨ë¸ ì ìš© ì‹¤íŒ¨, ê°•í™” ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©:', error);
                        separatedData = await this.advancedChorusRemoval(stftData);
                    }
                } else {
                    separatedData = await this.advancedChorusRemoval(stftData);
                }

                this.updateProgress(70, 'ISTFT ë³€í™˜ ì¤‘...');
                
                const processedBuffer = await this.performISTFT(separatedData, audioBuffer.sampleRate);
                
                stftData.dispose();
                if (separatedData !== stftData) separatedData.dispose();
                
                return processedBuffer;
            }

            async performSTFT(leftChannel, rightChannel) {
                const windowSize = 2048;
                const hopSize = windowSize / 4;
                const numFrames = Math.floor((leftChannel.length - windowSize) / hopSize) + 1;
                
                // ì‹¤ì œ FFT êµ¬í˜„ (ê°„ì†Œí™”ëœ ë²„ì „)
                const spectrogram = new Float32Array(numFrames * (windowSize / 2 + 1) * 2); // ì‹¤ìˆ˜ë¶€, í—ˆìˆ˜ë¶€
                
                // í•´ë° ìœˆë„ìš°
                const window = new Float32Array(windowSize);
                for (let i = 0; i < windowSize; i++) {
                    window[i] = 0.54 - 0.46 * Math.cos(2 * Math.PI * i / (windowSize - 1));
                }
                
                for (let frame = 0; frame < numFrames; frame++) {
                    const startIdx = frame * hopSize;
                    
                    // ìœˆë„ìš° ì ìš© í›„ FFT (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ FFT í•„ìš”)
                    for (let bin = 0; bin < windowSize / 2 + 1; bin++) {
                        const idx = frame * (windowSize / 2 + 1) * 2 + bin * 2;
                        
                        // ì¢Œìš° ì±„ë„ì˜ ë³µì†Œìˆ˜ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
                        let realPart = 0, imagPart = 0;
                        for (let k = 0; k < windowSize && startIdx + k < leftChannel.length; k++) {
                            const angle = -2 * Math.PI * bin * k / windowSize;
                            const leftSample = leftChannel[startIdx + k] * window[k];
                            const rightSample = rightChannel[startIdx + k] * window[k];
                            const sample = (leftSample + rightSample) / 2;
                            
                            realPart += sample * Math.cos(angle);
                            imagPart += sample * Math.sin(angle);
                        }
                        
                        spectrogram[idx] = realPart;
                        spectrogram[idx + 1] = imagPart;
                    }
                }
                
                return tf.tensor3d(spectrogram, [1, numFrames, (windowSize / 2 + 1) * 2]);
            }

            async performISTFT(stftData, sampleRate) {
                const windowSize = 2048;
                const hopSize = windowSize / 4;
                const stftShape = stftData.shape;
                const numFrames = stftShape[1];
                const numBins = stftShape[2] / 2;
                
                const outputLength = (numFrames - 1) * hopSize + windowSize;
                const outputBuffer = this.audioContext.createBuffer(1, outputLength, sampleRate);
                const outputData = outputBuffer.getChannelData(0);
                
                const stftArray = await stftData.data();
                
                // í•´ë° ìœˆë„ìš°
                const window = new Float32Array(windowSize);
                for (let i = 0; i < windowSize; i++) {
                    window[i] = 0.54 - 0.46 * Math.cos(2 * Math.PI * i / (windowSize - 1));
                }
                
                for (let frame = 0; frame < numFrames; frame++) {
                    const startIdx = frame * hopSize;
                    
                    // IFFT (ê°„ì†Œí™”ëœ êµ¬í˜„)
                    for (let n = 0; n < windowSize && startIdx + n < outputLength; n++) {
                        let sample = 0;
                        for (let bin = 0; bin < numBins; bin++) {
                            const idx = frame * numBins * 2 + bin * 2;
                            const real = stftArray[idx];
                            const imag = stftArray[idx + 1];
                            const angle = 2 * Math.PI * bin * n / windowSize;
                            sample += real * Math.cos(angle) - imag * Math.sin(angle);
                        }
                        outputData[startIdx + n] += sample * window[n] / windowSize;
                    }
                }
                
                return outputBuffer;
            }

            async applyMask(stftData, mask) {
                const maskArray = await mask.data();
                const stftArray = await stftData.data();
                const maskedData = new Float32Array(stftArray.length);
                
                for (let i = 0; i < stftArray.length; i += 2) {
                    const maskValue = maskArray[Math.floor(i / 2)];
                    maskedData[i] = stftArray[i] * maskValue;
                    maskedData[i + 1] = stftArray[i + 1] * maskValue;
                }
                
                return tf.tensor3d(maskedData, stftData.shape);
            }

            async advancedVocalRemoval(stftData) {
                const stftArray = await stftData.data();
                const processedData = new Float32Array(stftArray.length);
                const shape = stftData.shape;
                const numFrames = shape[1];
                const numBins = shape[2] / 2;
                
                // ê³ ê¸‰ ë³´ì»¬ ì œê±° ì•Œê³ ë¦¬ì¦˜
                for (let frame = 0; frame < numFrames; frame++) {
                    for (let bin = 0; bin < numBins; bin++) {
                        const idx = frame * numBins * 2 + bin * 2;
                        const real = stftArray[idx];
                        const imag = stftArray[idx + 1];
                        const magnitude = Math.sqrt(real * real + imag * imag);
                        const phase = Math.atan2(imag, real);
                        
                        // ì¤‘ì•™ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì—ì„œ ë³´ì»¬ ì œê±° (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)
                        let attenuation = 1.0;
                        if (bin > numBins * 0.1 && bin < numBins * 0.8) {
                            // ì£¼íŒŒìˆ˜ ì„ íƒì  ê°ì‡ 
                            const vocalRange = Math.exp(-Math.pow((bin - numBins * 0.3) / (numBins * 0.2), 2));
                            attenuation = Math.max(0.1, 1.0 - vocalRange * 0.9);
                        }
                        
                        const newMagnitude = magnitude * attenuation;
                        processedData[idx] = newMagnitude * Math.cos(phase);
                        processedData[idx + 1] = newMagnitude * Math.sin(phase);
                    }
                }
                
                return tf.tensor3d(processedData, shape);
            }

            async advancedChorusRemoval(stftData) {
                const stftArray = await stftData.data();
                const processedData = new Float32Array(stftArray.length);
                const shape = stftData.shape;
                const numFrames = shape[1];
                const numBins = shape[2] / 2;
                
                // ë” ê°•ë ¥í•œ ì½”ëŸ¬ìŠ¤ ì œê±° ì•Œê³ ë¦¬ì¦˜
                for (let frame = 0; frame < numFrames; frame++) {
                    for (let bin = 0; bin < numBins; bin++) {
                        const idx = frame * numBins * 2 + bin * 2;
                        const real = stftArray[idx];
                        const imag = stftArray[idx + 1];
                        const magnitude = Math.sqrt(real * real + imag * imag);
                        const phase = Math.atan2(imag, real);
                        
                        // ë³´ì»¬ ë° ì½”ëŸ¬ìŠ¤ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì—ì„œ ê°•í•œ ê°ì‡ 
                        let attenuation = 1.0;
                        
                        // ê¸°ë³¸ ë³´ì»¬ ëŒ€ì—­ (200Hz - 2kHz)
                        if (bin > numBins * 0.05 && bin < numBins * 0.6) {
                            const vocalAttenuation = Math.exp(-Math.pow((bin - numBins * 0.25) / (numBins * 0.15), 2));
                            attenuation *= Math.max(0.05, 1.0 - vocalAttenuation * 0.95);
                        }
                        
                        // ì½”ëŸ¬ìŠ¤ ë° í•˜ëª¨ë‹ˆ ëŒ€ì—­ (ë” ë„“ì€ ë²”ìœ„)
                        if (bin > numBins * 0.08 && bin < numBins * 0.75) {
                            const chorusAttenuation = Math.exp(-Math.pow((bin - numBins * 0.4) / (numBins * 0.25), 2));
                            attenuation *= Math.max(0.08, 1.0 - chorusAttenuation * 0.85);
                        }
                        
                        // ê³ ì¡°íŒŒ ì œê±°
                        for (let harmonic = 2; harmonic <= 4; harmonic++) {
                            const harmonicBin = bin / harmonic;
                            if (harmonicBin > numBins * 0.1 && harmonicBin < numBins * 0.3) {
                                attenuation *= 0.7;
                            }
                        }
                        
                        const newMagnitude = magnitude * attenuation;
                        processedData[idx] = newMagnitude * Math.cos(phase);
                        processedData[idx + 1] = newMagnitude * Math.sin(phase);
                    }
                }
                
                return tf.tensor3d(processedData, shape);
            }

            async audioBufferToBlob(audioBuffer) {
                const numberOfChannels = audioBuffer.numberOfChannels;
                const length = audioBuffer.length;
                const sampleRate = audioBuffer.sampleRate;
                
                // WAV íŒŒì¼ ìƒì„±
                const buffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
                const view = new DataView(buffer);
                
                // WAV í—¤ë” ì‘ì„±
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };
                
                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * numberOfChannels * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, numberOfChannels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * numberOfChannels * 2, true);
                view.setUint16(32, numberOfChannels * 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * numberOfChannels * 2, true);
                
                // ì˜¤ë””ì˜¤ ë°ì´í„° ì‘ì„± (ì •ê·œí™” ë° í´ë¦¬í•‘ ì ìš©)
                let offset = 44;
                for (let i = 0; i < length; i++) {
                    for (let channel = 0; channel < numberOfChannels; channel++) {
                        let sample = audioBuffer.getChannelData(channel)[i];
                        
                        // ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ ì ìš©
                        if (Math.abs(sample) < 0.001) sample = 0;
                        
                        // ì†Œí”„íŠ¸ í´ë¦¬í•‘
                        sample = Math.max(-1, Math.min(1, sample));
                        if (sample > 0.95) sample = 0.95 + (sample - 0.95) * 0.2;
                        if (sample < -0.95) sample = -0.95 + (sample + 0.95) * 0.2;
                        
                        const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                        view.setInt16(offset, intSample, true);
                        offset += 2;
                    }
                }
                
                return new Blob([buffer], { type: 'audio/wav' });
            }

            displayResult(processedBlob, processedBuffer) {
                this.processedAudioBuffer = processedBuffer;
                
                const processedAudio = document.getElementById('processedAudio');
                processedAudio.src = URL.createObjectURL(processedBlob);
                
                // ê²°ê³¼ íŒ¨ë„ í‘œì‹œ
                document.getElementById('audioPlayer').style.display = 'block';
                
                // ë¶€ë“œëŸ¬ìš´ ìŠ¤í¬ë¡¤
                document.getElementById('audioPlayer').scrollIntoView({
                    behavior: 'smooth',
                    block: 'center'
                });
            }

            downloadProcessedAudio() {
                if (!this.processedAudioBuffer) return;
                
                this.audioBufferToBlob(this.processedAudioBuffer).then(blob => {
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    
                    const methodName = this.currentMethod === 'vocal' ? 'vocal_removed' : 'chorus_removed';
                    const timestamp = new Date().toISOString().slice(0, 19).replace(/[:\-]/g, '');
                    a.download = `${methodName}_${timestamp}.wav`;
                    
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                    
                    this.updateStatus('ğŸ’¾ íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!');
                });
            }

            updateStatus(message) {
                document.getElementById('status').innerHTML = message;
            }

            showProgress() {
                document.getElementById('progressContainer').style.display = 'block';
                document.getElementById('processBtn').disabled = true;
            }

            hideProgress() {
                document.getElementById('progressContainer').style.display = 'none';
                document.getElementById('processBtn').disabled = false;
            }

            updateProgress(percent, text = '') {
                document.getElementById('progressFill').style.width = percent + '%';
                if (text) {
                    document.getElementById('progressText').textContent = text;
                }
                
                if (percent >= 100) {
                    setTimeout(() => {
                        this.hideProgress();
                    }, 2000);
                }
            }
        }

        // ì•± ì´ˆê¸°í™”
        document.addEventListener('DOMContentLoaded', () => {
            new AdvancedVocalRemover();
        });
    </script>
</body>
</html>